{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e829e25d-834d-431e-b0ec-12896686b832",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a2e932-2f41-40ce-a8d3-02118b9ba660",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SPARK_LOCAL_IP\"] = \"127.0.0.1\" # Выпадало предупреждение при создании Спарк Сессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62c7a2c5-0f55-4696-b1b4-60f7141d98ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ClickHouseToPySpark\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.clickhouse:clickhouse-jdbc:0.9.6\") \\\n",
    "    .config(\"spark.driver.extraJavaOptions\", \"--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED\") \\\n",
    "    .config(\"spark.executor.extraJavaOptions\", \"--add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09ea240-2c51-43a1-ab24-71e24f6b9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_options_purcases = {\n",
    "    \"url\": \"jdbc:clickhouse://localhost:9123/silver\",\n",
    "    \"user\": \"user\",            # логин из docker-compose\n",
    "    \"password\": \"strongpassword\", # пароль\n",
    "    \"dbtable\": \"purchases\",     # таблица, которую хочешь забрать\n",
    "    \"driver\": \"com.clickhouse.jdbc.ClickHouseDriver\"\n",
    "}\n",
    "\n",
    "# Создаем ДФ с покупками\n",
    "df_purchases = spark.read.format(\"jdbc\").options(**ch_options_purcases).load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ec8985-e10f-413a-9636-64877da345a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оказывается Спарк не хочет читать Array(категории) и Tuple(координаты), поэтому на этапе выгрузки подменяем саму таблицу stores\n",
    "# на select запрос, в котором склеиваем (или дропаем) значения, в качестве обучения я склеил категории и дропнул координаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0848bf5-4c34-4cec-9210-6c5b4eee36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"(SELECT store_id, store_name, store_network, store_description, type, arrayStringConcat(categories, ', ') as categories_str, manager_name, manager_phone, manager_email, country, city, street, house, postal_code, accept_online_orders, delivery_available, warehouse_connected, last_inventory_date, load_datetime FROM silver.stores) AS t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5777fa4-0637-45e8-ac26-9b451bbe1568",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_options_stores = {\n",
    "    \"url\": \"jdbc:clickhouse://localhost:9123/silver\",\n",
    "    \"user\": \"user\",            # логин из docker-compose\n",
    "    \"password\": \"strongpassword\", # пароль\n",
    "    \"dbtable\": request,     # таблица, которую хочешь забрать\n",
    "    \"driver\": \"com.clickhouse.jdbc.ClickHouseDriver\"\n",
    "    #\"customSchema\": f\"{purchase_schema}\"\n",
    "}\n",
    "\n",
    "# Создаем ДФ с магазинами\n",
    "df_stores = spark.read.format(\"jdbc\").options(**ch_options_stores).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0c761a1-883b-45a1-9883-67a807566ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_options_customers = {\n",
    "    \"url\": \"jdbc:clickhouse://localhost:9123/silver\",\n",
    "    \"user\": \"user\",            # логин из docker-compose\n",
    "    \"password\": \"strongpassword\", # пароль\n",
    "    \"dbtable\": \"customers\",     # таблица, которую хочешь забрать\n",
    "    \"driver\": \"com.clickhouse.jdbc.ClickHouseDriver\"\n",
    "    #\"customSchema\": f\"{purchase_schema}\"\n",
    "}\n",
    "\n",
    "# Создаем ДФ с покупателями\n",
    "df_customers = spark.read.format(\"jdbc\").options(**ch_options_stores).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c5a63c-7d83-4fc8-9292-78699f248127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d390067e-2241-44b3-888b-09c2fc19ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_options_products = {\n",
    "    \"url\": \"jdbc:clickhouse://localhost:9123/silver\",\n",
    "    \"user\": \"user\",            # логин из docker-compose\n",
    "    \"password\": \"strongpassword\", # пароль\n",
    "    \"dbtable\": \"products\",     # таблица, которую хочешь забрать\n",
    "    \"driver\": \"com.clickhouse.jdbc.ClickHouseDriver\"\n",
    "    #\"customSchema\": f\"{purchase_schema}\"\n",
    "}\n",
    "\n",
    "# Создаем ДФ с продуктами\n",
    "df_products = spark.read.format(\"jdbc\").options(**ch_options_stores).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c7051-3102-4a47-ade0-c535b50af4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defc1e85-6e81-45a8-9737-63d57581d93c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
